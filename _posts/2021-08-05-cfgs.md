---
title: Control-flow graphs
layout: post
date: 2021-08-05 00:00:00 PT
description: Creating control-flow graphs from bytecode and abstract interpretation
---

In this post, I'm going to demonstrate how to build a small control-flow graph
(CFG) implementation from stack-based bytecode. To get the most out of this
post, it is helpful to have an idea about how bytecode-based virtual machines
(VMs) work. If you are unfamiliar, or want a refresher, I recommend taking a
look at my post about [bytecode interpreters][bytecode-interpreters] or the
["Runtimes" section][runtimes] of my programming languages resources page.

[bytecode-interpreters]: /blog/bytecode-interpreters/
[runtimes]: /pl-resources/#runtimes

We'll build the CFG in two steps: 1) find basic block boundaries, and 2)
transform the stack-based bytecode into a virtual register-based intermediate
representation (IR). This form is useful for optimizations and transformations,
like [converting to static single assignment (SSA)][ssa].

[ssa]: /assets/img/braun13cc.pdf

But first we have to start with bytecode[^ast]. Since I'm reasonably familiar
with it, I'm going to use a reduced variant of CPython 3.7 bytecode. This
incidentally means that you could adapt the sample code in this post to build a
CFG from a subset of Python!

## The bytecode

When I said "reduced variant of CPython 3.7", I meant *very* reduced. For the
purposes of this post, we're only going to look at five different opcodes: one
for math; one for constants in the instruction stream; one for local variables;
one for control flow; and one for returning values.

```python
class Op:
    # Pop the top two item off the stack. Add them. Push the result.
    BINARY_ADD = 23
    # Pop the top item off the stack. Return to the caller. Push the item.
    RETURN_VALUE = 83
    # Fetch the constant at index specified by the argument and push it.
    LOAD_CONST = 100
    # Fetch the local at the index specified by the argument and push it.
    LOAD_FAST = 124
    # Pop the top item off the stack. Jump to the bytecode index specified by
    # the argument if the item is false. Otherwise, continue.
    POP_JUMP_IF_FALSE = 114
```

Adding support for other opcodes should be reasonably similar[^exceptions], and
in fact I may reference others in the body of the post, but we'll only
translate the above opcodes to our IR.

> "But Max," you might ask, "why have you assigned these symbolic constants
> such strange numbers?" I leave this as an exercise for the reader.

Each opcode takes an integer argument, which is left the opcode handler to
interpret. Some opcodes, like `RETURN_VALUE`, even ignore their arguments.

Let's take a look at a simple "hello world" program that loads a constant from
the constant pool and then returns from the current function to the caller.

```
LOAD_CONST   0
RETURN_VALUE 0
```

Runtimes like CPython choose to model bytecode programs as byte arrays for
compactness. In CPython, this program might look like:

```
64 00 53 00
```

For the purposes of this post, we will model the bytecode as a list of
`BytecodeOp` objects. This helps with readability and will look like:

```python
[
  BytecodeOp(Op.LOAD_CONST, 0, 0),
  BytecodeOp(Op.RETURN_VALUE, 0, 1),
]
```

The symbolic meaning is the same.

Let's take a look at the `BytecodeOp` class and figure out what that third
argument is:

```python
class BytecodeOp:
    def __init__(self, op: int, arg: int, idx: int) -> None:
        self.op: int = op
        self.arg: int = arg
        self.idx: int = idx

    # [...]
```

Each `BytecodeOp` in a function will carry an opcode, its argument, and its
index into the list of `BytecodeOp`s for the current function. The index will
be helpful later when finding basic block boundaries.

Since a list of `BytecodeOp`s does not alone describe a bit of
code[^realistic-code], we will also carry around other context. Code objects
have other attributes such as a constant pool that we must also represent for
opcodes like `LOAD_CONST`:

```python
class Code:
    def __init__(
        self,
        bytecode: List[BytecodeOp],
        nlocals: int,
        nargs: int,
        consts: Tuple[Any, ...] = (),
    ) -> None:
        self.bytecode: List[BytecodeOp] = bytecode
        self.nlocals: int = nlocals
        self.nargs: int = nargs
        self.consts: Tuple[Any, ...] = consts
```

To put it all together: we represent code with `Code` objects that hold lists
of `BytecodeOp`s.

## Finding basic block boundaries

```python
def main() -> None:
    bytecode = [BytecodeOp(op, arg, idx) for (idx, (op, arg)) in enumerate(simple_if)]
    code = Code(bytecode, nlocals=1, nargs=1, consts=(None, 1, 2))
    bc_instrs = BytecodeInstructionBlock(bytecode)
    func = Function(code, bc_instrs)
    block_map = create_blocks(func)
    entry_block = get_entry_block(func)
    func.cfg.entry_block = entry_block

    entry_tc = TranslationContext(entry_block)
    emit_prelude(func, entry_tc)

    first_block = block_map.blocks[0]
    if entry_block != first_block:
        entry_block.append(Branch(first_block))

    entry_tc.block = first_block
    translate(func, entry_tc)
    print(func.cfg)
```

<hr style="width: 100px;" />
<!-- Footnotes -->

[^ast]: We don't *have* to start with bytecode. People do create CFGs directly
        from ASTs sometimes. In fact, that's what the linked [SSA paper][ssa]
        does. Some people also create CFGs from machine code as part of a
        reverse engineering process. But a common technique for optimizing
        runtimes (like the JVM, V8, .NET, etc) is to start from bytecode and
        optimize from there.

[^exceptions]: This gets a little trickier with exceptions, so I won't cover
               exceptions in this post. Maybe once I understand how to model
               exception control flow better, I will either update the post or
               write a new one.

[^realistic-code]: I suppose we could technically make the bytecode fully
                   self-describing, with inline metadata, etc, but the goal of
                   this post was to describe a real-world bytecode format used
                   in runtimes such as CPython.
