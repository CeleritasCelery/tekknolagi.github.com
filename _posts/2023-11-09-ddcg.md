---
title: A quick look at destination-driven code generation
layout: post
description: idk yet
date: 2023-11-09
---

Register allocation is tricky

Let's write a silly compiler in Python and see if we can improve the generated
code

We will use a small math language that supports constant integers, addition,
and multiplication

```python
# Ignore the @ir decorator. It's not important except for some dataclasses
# shenanigans.
@ir
class Instr:
    # ...
    pass


@ir
class Const(Instr):
    value: int

    def __repr__(self):
        return f"{self.var()} = {self.value}"


@ir
class Binary(Instr):
    left: Instr
    right: Instr

    def operands(self):
        return (self.left, self.right)


@ir
class Add(Binary):
    pass


@ir
class Mul(Binary):
    pass
```

We're going to pretend that we can't constant-fold these expressions to one
number because that's not the point of this post.

The IR's text form will look like this:

```
v0 = 2
v1 = 3
v2 = Add v0, v1
```

Nothing too fancy. No control-flow. No function calls. No data structures.

We can write a recursive tree-walking evaluator for this IR in a couple lines
of code:

```python
def eval_exp(exp):
    if isinstance(exp, Const):
        return exp.value
    elif isinstance(exp, Add):
        left = eval_exp(exp.left)
        right = eval_exp(exp.right)
        return left + right
    elif isinstance(exp, Mul):
        left = eval_exp(exp.left)
        right = eval_exp(exp.right)
        return left * right
    else:
        raise NotImplementedError(f"unexpected exp {exp}")
```

And the corresponding tree-walking compiler to x86-64 looks similar enough if
you squint:

```python
def naive_compile(exp):
    if isinstance(exp, Const):
        return [X86.Mov(RAX, Imm(exp.value))]
    elif isinstance(exp, Add):
        right_code = naive_compile(exp.right)
        left_code = naive_compile(exp.left)
        return [
            *right_code,
            X86.Push(RAX),
            *left_code,
            X86.Pop(RCX),
            X86.Add(RAX, RCX),
        ]
    elif isinstance(exp, (Add, Mul)):
        right_code = naive_compile(exp.right)
        left_code = naive_compile(exp.left)
        return [
            *right_code,
            X86.Push(RAX),
            *left_code,
            X86.Pop(RCX),
            X86.Mul(RAX, RCX),
        ]
    else:
        raise NotImplementedError(f"unexpected exp {exp}")
```

With each case, our goal is to get the result into the register RAX. In the
constant case, we emit one instruction to move the value---the immediate---into
RAX.

In the recursive binary cases, we generate code for the left and right side of
the expression. We put the compiled code for the right hand side first, then
for the left hand side.

Since both cases will try to put the result in RAX, we have to stash the result
from the right hand side in a temporary location: the stack. Then, when it
comes time to add it, we can fetch it from the stack into a register.

This works because we maintain two invariants:

* Within a compiler case, we have the same stack pointer across calls. That is,
  recursive calls to the compiler may change it about but the code should
  eventually restore the stack to what we gave it.
* All cases only use our temporary, RCX, as a temporary and don't try to stick
  anything long-lived in it.

So what does the generated code look like? I will answer in the form of unit
tests.

Let's look at `Const` first:

```python
class NaiveCompilerTests(unittest.TestCase):
    def _alloc(self, exp):
        x86 = naive_compile(exp)
        return [str(op) for op in x86]

    def test_const(self):
        exp = Const(2)
        self.assertEqual(
            self._alloc(exp),
            ["X86.Mov(dst=rax, src=Imm(2))"],
        )
```

Right. Nice. Just about what we expected.

And now the binary cases:

```python
class NaiveCompilerTests(unittest.TestCase):
    # ...
    def test_add(self):
        exp = Add(Const(2), Const(3))
        self.assertEqual(
            self._alloc(exp),
            [
                "X86.Mov(dst=rax, src=Imm(3))",
                "X86.Push(src=rax)",
                "X86.Mov(dst=rax, src=Imm(2))",
                "X86.Pop(dst=rcx)",
                "X86.Add(dst=rax, src=rcx)",
            ],
        )

    def test_mul(self):
        exp = Mul(Const(2), Const(3))
        self.assertEqual(
            self._alloc(exp),
            [
                "X86.Mov(dst=rax, src=Imm(3))",
                "X86.Push(src=rax)",
                "X86.Mov(dst=rax, src=Imm(2))",
                "X86.Pop(dst=rcx)",
                "X86.Mul(dst=rax, src=rcx)",
            ],
        )
```

Hmm. You know, now that I look at it, maybe moving everything to RAX was not
the right answer. It kind of looks like there is a lot of data movement going
on. I guess it can't be helped.

And one more test with deeper nesting, for good measure:

```python
class NaiveCompilerTests(unittest.TestCase):
    # ...
    def test_mul_add(self):
        exp = Mul(
            Add(Const(1), Const(2)),
            Add(Const(3), Const(4)),
        )
        self.assertEqual(
            self._alloc(exp),
            [
                "X86.Mov(dst=rax, src=Imm(4))",
                "X86.Push(src=rax)",
                "X86.Mov(dst=rax, src=Imm(3))",
                "X86.Pop(dst=rcx)",
                "X86.Add(dst=rax, src=rcx)",
                "X86.Push(src=rax)",
                "X86.Mov(dst=rax, src=Imm(2))",
                "X86.Push(src=rax)",
                "X86.Mov(dst=rax, src=Imm(1))",
                "X86.Pop(dst=rcx)",
                "X86.Add(dst=rax, src=rcx)",
                "X86.Pop(dst=rcx)",
                "X86.Mul(dst=rax, src=rcx)",
            ],
        )
```

Actually, yikes, I take it back. We have to do something about this. The code
exploded. So what's to be done?

We could write a full register allocator like linear scan or graph
coloring[^ssa-chordal], but that sounds like a lot of work. Also, sometimes
(like in a baseline compiler) your code generation needs to be really fast and
those don't fit the performance budget.

[^ssa-chordal]: Fun fact, despite optimal graph coloring normally being
    NP-complete, apparently [interference graphs of SSA programs are
    chordal](https://compilers.cs.uni-saarland.de/projects/ssara/). And graph
    coloring of chordal graphs can be done in polynomial time. So since we have
    a SSA IR, we could do a "reasonably fast" graph coloring allocator. Maybe
    another time.

Thankfully, Dybvig and the gang are back with some cool ideas.

### Destination-driven code generation

The [paper](assets/img/ddcg.pdf) (PDF) is approachable enough, but if you want
an even more approachable introduction, there's a [great
talk](assets/img/46b-codegeneration-in-V8.pdf) (PDF) by Kevin Millikin
explaining how V8 implemented it in one of their first compilers.

The key insight is that in a recursive code generator, the caller of the
recursive compilation step knows where it wants the result of the callee to
go---so we should not be copying everything around through some result register
like RAX. We should instead pass the destination we want as a parameter.

For this post, there are two kinds of destinations: the stack and the
accumulator (RAX).

```python
class Dest:
    STACK = 0
    ACCUM = 1
```

And the destination-driven compiler looks *suspiciously similar* to the normal
tree-walking one:

```python
def ddcg_compile(code):
    return _ddcg_compile(code, Dest.ACCUM)

def _ddcg_compile(exp, dst):
    tmp = RCX
    if isinstance(exp, Const):
        return _plug_imm(dst, exp.value)
    elif isinstance(exp, Add):
        return [
            *_ddcg_compile(exp.left, Dest.STACK),
            *_ddcg_compile(exp.right, Dest.ACCUM),
            X86.Pop(tmp),
            X86.Add(RAX, tmp),
            *_plug_reg(dst, RAX),
        ]
    elif isinstance(exp, Mul):
        return [
            *_ddcg_compile(exp.left, Dest.STACK),
            *_ddcg_compile(exp.right, Dest.ACCUM),
            X86.Pop(tmp),
            X86.Mul(RAX, tmp),
            *_plug_reg(dst, RAX),
        ]
    else:
        raise NotImplementedError(exp)
```

It also does recursive compilation of the left and right cases. It does push
(via passing the stack destination) and pop. But it has these funny-looking
plug functions.

The plug functions

### Adding control destinations

### Adding a virtual stack
